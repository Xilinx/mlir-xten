//===- aten_conv2d_nobias.mlir ---------------------------------*- MLIR -*-===//
//
// This file is licensed under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
// (c) Copyright 2019 Xilinx Inc.
//
//===----------------------------------------------------------------------===//

// RUN: aten-opt %s -aten-to-xten | FileCheck %s
// CHECK:   %4 = "xten.conv2d"(%arg0, %0, %none, %1, %2, %3, %int1) {layer_name = "Conv_0"} : (!torch.vtensor<[1,2,128,128],f32>, !torch.vtensor<[16,2,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.int) -> !torch.vtensor<[1,16,128,128],f32>
module attributes {torch.debug_module_name = "model"}  {
  func.func @forward(%arg0: !torch.vtensor<[1,2,128,128],f32>) -> !torch.vtensor<[1,16,128,128],f32> {
    %int1 = torch.constant.int 1
    %0 = torch.vtensor.literal(dense<"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tensor<16x2x3x3xf32>) : !torch.vtensor<[16,2,3,3],f32>
    %none = torch.constant.none
    %false = torch.constant.bool false
    %1 = torch.prim.ListConstruct %int1, %int1 : (!torch.int, !torch.int) -> !torch.list<int>
    %2 = torch.prim.ListConstruct %int1, %int1 : (!torch.int, !torch.int) -> !torch.list<int>
    %3 = torch.prim.ListConstruct %int1, %int1 : (!torch.int, !torch.int) -> !torch.list<int>
    %empty_list = torch.prim.ListConstruct : () -> !torch.list<int>
    %4 = torch.aten.convolution %arg0, %0, %none, %1, %2, %3, %false, %empty_list, %int1 {layer_name = "Conv_0"} : !torch.vtensor<[1,2,128,128],f32>, !torch.vtensor<[16,2,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,16,128,128],f32>
    return %4 : !torch.vtensor<[1,16,128,128],f32>
  }
}
